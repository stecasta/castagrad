{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedLayer():\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        np.random.seed(42)\n",
    "        # Initialize weights and biases with Xavier initialization\n",
    "        self.w = np.random.normal(loc=0, scale=1/np.sqrt(self.input_size), size=(self.input_size, self.output_size))\n",
    "        self.b = np.random.normal(loc=0, scale=1/np.sqrt(self.input_size), size=(self.output_size))\n",
    "    def __call__(self, x):\n",
    "        y = np.matmul(x, self.w) + self.b\n",
    "        return y\n",
    "    def backward(self, grad, x):\n",
    "        self.grad_w = np.outer(x, grad)\n",
    "        self.grad_b = grad\n",
    "        return self.grad_w, self.grad_b\n",
    "    def update(self, learning_rate=0.01):\n",
    "        self.w -= learning_rate * self.grad_w \n",
    "        self.b -= learning_rate * self.grad_b\n",
    "\n",
    "class Sigmoid():\n",
    "    def __call__(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    def backward(self, grad, x):\n",
    "        if len(grad.shape) > 1:\n",
    "            grad = np.sum(grad, axis=1)\n",
    "        return grad * (np.exp(-x)) / (1 + np.exp(-x))**2\n",
    "\n",
    "class MSE():\n",
    "    def __call__(self, y_pred, y_gt):\n",
    "        return (y_gt - y_pred)**2\n",
    "    def backward(self, y_pred, y_gt):\n",
    "        return 2 * (y_pred - y_gt)\n",
    "\n",
    "class Layer():\n",
    "    def __init__(self, fcl):\n",
    "        self.fcl = fcl\n",
    "\n",
    "class MLP():\n",
    "    def __init__(self, layers_sizes):\n",
    "        self.layers_sizes = layers_sizes\n",
    "        self.sigmoid = Sigmoid()\n",
    "        self.mse = MSE()\n",
    "        self.layers = []\n",
    "        for i in range(len(layers_sizes) - 1):\n",
    "            fcl = FullyConnectedLayer(layers_sizes[i], layers_sizes[i+1])\n",
    "            self.layers.append(Layer(fcl))\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            layer.input = x\n",
    "            layer.fcl_out = layer.fcl(x)\n",
    "            layer.sigmoid_out = self.sigmoid(layer.fcl_out)\n",
    "            x = layer.sigmoid_out\n",
    "        return x\n",
    "    def backward(self, y_gt):\n",
    "        grad = self.mse.backward(self.layers[-1].sigmoid_out, y_gt)\n",
    "        for layer in reversed(self.layers):\n",
    "            grad_sigmoid = self.sigmoid.backward(grad, layer.fcl_out)\n",
    "            grad, _ = layer.fcl.backward(grad_sigmoid, layer.input)\n",
    "    def update(self, learning_rate=0.01):\n",
    "        for layer in self.layers:\n",
    "            layer.fcl.update(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 1, 1])\n",
    "y_gt = np.array([1, 1])\n",
    "input_size = len(x)\n",
    "output_size = len(y_gt)\n",
    "\n",
    "mlp = MLP([input_size, 10, 10, 10, 10, output_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:14<00:00, 7072.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99424789 0.99433034]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "n_epochs = 100000\n",
    "\n",
    "for i in tqdm.tqdm(range(n_epochs)):\n",
    "    y = mlp(x)\n",
    "    loss = mlp.mse(y, y_gt)\n",
    "    mlp.backward(y_gt)\n",
    "    mlp.update()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: (3,), output shape: (2,)\n",
      "input: [1 1 1]\n",
      "output: [1 1]\n",
      "----------------------------------------------------------------\n",
      "Weights: [[ 0.28677805 -0.07982693]\n",
      " [ 0.37394315  0.8793217 ]\n",
      " [-0.13518851 -0.13517904]]\n",
      "Biases: [0.91175894 0.44307865]\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 1, 1])\n",
    "y_gt = np.array([1, 1])\n",
    "\n",
    "input_size = len(x)\n",
    "output_size = len(y_gt)\n",
    "print(f\"input shape: {x.shape}, output shape: {y.shape}\")\n",
    "print(f\"input: {x}\")\n",
    "print(f\"output: {y}\")\n",
    "print(\"----------------------------------------------------------------\")\n",
    "\n",
    "fcl = FullyConnectedLayer(input_size, output_size)\n",
    "print(f\"Weights: {fcl.w}\")\n",
    "print(f\"Biases: {fcl.b}\")\n",
    "print(\"----------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out sigmoid: [0.97401082 0.9738612 ]\n",
      "out_mse: [0.00067544 0.00068324]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "n_epochs = 100000\n",
    "\n",
    "for i in range(1, n_epochs):\n",
    "    # Forward\n",
    "    out_fcl = fcl(x)\n",
    "\n",
    "    sigmoid = Sigmoid()\n",
    "    out_sigmoid = sigmoid(out_fcl)\n",
    "    # print(f\"Out sigmoid: {out_sigmoid}\")\n",
    "\n",
    "    mse = MSE()\n",
    "    out_mse = mse(out_sigmoid, y_gt)\n",
    "    # print(\"--------------------------------\")\n",
    "\n",
    "    # Backward\n",
    "    grad_loss = mse.backward(out_sigmoid, y_gt)\n",
    "    # print(f\"grad_loss: {grad_loss}\")\n",
    "    grad_activation = sigmoid.backward(grad_loss, out_fcl)\n",
    "    # print(f\"grad_activation: {grad_activation}\")\n",
    "    fcl.backward(grad_activation, x)\n",
    "    fcl.update(learning_rate=learning_rate)\n",
    "    # print(f\"Weights: {fcl.w}\")\n",
    "    # print(f\"Biases: {fcl.b}\")\n",
    "\n",
    "print(f\"Out sigmoid: {out_sigmoid}\")\n",
    "print(f\"out_mse: {out_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "castagrad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
